{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé® Creative Neural Architecture Search - Interactive Demo\n",
    "\n",
    "This notebook provides an interactive way to discover creative neural network architectures.\n",
    "\n",
    "**Estimated time:** 3-10 minutes depending on settings\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (run once)\n",
    "# !pip install torch torchvision torch-geometric networkx scipy matplotlib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from datetime import datetime\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check GPU availability\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"üñ•Ô∏è  Using device: {device}\")\n",
    "if device == 'cpu':\n",
    "    print(\"‚ö†Ô∏è  No GPU detected. Training will be slower. Recommend using MNIST with fewer episodes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration\n",
    "\n",
    "**Customize your demo here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== DEMO CONFIGURATION =====\n",
    "\n",
    "# Dataset choice: 'mnist', 'fashion', 'cifar10'\n",
    "# - mnist: Fastest (~2-3 min for 50 episodes)\n",
    "# - fashion: Fast (~3-5 min for 50 episodes)  \n",
    "# - cifar10: Slower (~5-10 min for 50 episodes)\n",
    "DATASET = 'mnist'\n",
    "\n",
    "# Number of training episodes (50-200 for demo)\n",
    "# More episodes = more exploration but longer time\n",
    "EPISODES = 100\n",
    "\n",
    "# Epochs per architecture evaluation (2-5 for demo)\n",
    "# More epochs = better accuracy estimates but slower\n",
    "EVAL_EPOCHS = 3\n",
    "\n",
    "# Number of top architectures to fully evaluate (5-20)\n",
    "TOP_K = 10\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = f'demo_results/{DATASET}_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "\n",
    "print(\"üìã Configuration:\")\n",
    "print(f\"  Dataset: {DATASET}\")\n",
    "print(f\"  Episodes: {EPISODES}\")\n",
    "print(f\"  Eval Epochs: {EVAL_EPOCHS}\")\n",
    "print(f\"  Top K: {TOP_K}\")\n",
    "print(f\"  Output: {OUTPUT_DIR}\")\n",
    "\n",
    "# Estimate time\n",
    "time_estimates = {\n",
    "    'mnist': EPISODES * 0.02 + TOP_K * 0.15,\n",
    "    'fashion': EPISODES * 0.025 + TOP_K * 0.2,\n",
    "    'cifar10': EPISODES * 0.04 + TOP_K * 0.4\n",
    "}\n",
    "print(f\"\\n‚è±Ô∏è  Estimated time: ~{time_estimates[DATASET]:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Load Core Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all modules\n",
    "from architecture import ArchitectureState, ActionSpace, OPERATION_POOL\n",
    "from gnn_models import ArchitectureEncoder, DQNetwork\n",
    "from novelty import TopologicalNovelty, ScaleNovelty, RewardFunction\n",
    "from evaluation import ConvNet, train_architecture\n",
    "from agent import CreativityDQN\n",
    "from utils import save_all_results, load_architecture_json\n",
    "from visualize import visualize_architecture, create_results_report\n",
    "\n",
    "print(\"‚úÖ All modules loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Configure Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluation\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "\n",
    "if DATASET == 'mnist':\n",
    "    def get_mnist_loaders(batch_size=128, subset_size=None):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(32),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "            transforms.Normalize((0.1307,)*3, (0.3081,)*3)\n",
    "        ])\n",
    "        \n",
    "        trainset = torchvision.datasets.MNIST(\n",
    "            root='./data', train=True, download=True, transform=transform\n",
    "        )\n",
    "        testset = torchvision.datasets.MNIST(\n",
    "            root='./data', train=False, download=True, transform=transform\n",
    "        )\n",
    "        \n",
    "        if subset_size:\n",
    "            indices = np.random.choice(len(trainset), subset_size, replace=False)\n",
    "            trainset = Subset(trainset, indices)\n",
    "        \n",
    "        return (DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2),\n",
    "               DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2))\n",
    "    \n",
    "    evaluation.get_cifar10_loaders = get_mnist_loaders\n",
    "    print(\"üìä Dataset: MNIST (handwritten digits)\")\n",
    "\n",
    "elif DATASET == 'fashion':\n",
    "    def get_fashion_loaders(batch_size=128, subset_size=None):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(32),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "            transforms.Normalize((0.2860,)*3, (0.3530,)*3)\n",
    "        ])\n",
    "        \n",
    "        trainset = torchvision.datasets.FashionMNIST(\n",
    "            root='./data', train=True, download=True, transform=transform\n",
    "        )\n",
    "        testset = torchvision.datasets.FashionMNIST(\n",
    "            root='./data', train=False, download=True, transform=transform\n",
    "        )\n",
    "        \n",
    "        if subset_size:\n",
    "            indices = np.random.choice(len(trainset), subset_size, replace=False)\n",
    "            trainset = Subset(trainset, indices)\n",
    "        \n",
    "        return (DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2),\n",
    "               DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2))\n",
    "    \n",
    "    evaluation.get_cifar10_loaders = get_fashion_loaders\n",
    "    print(\"üìä Dataset: Fashion-MNIST (clothing items)\")\n",
    "\n",
    "else:\n",
    "    print(\"üìä Dataset: CIFAR-10 (natural images)\")\n",
    "\n",
    "# Override epochs for demo\n",
    "original_train = evaluation.train_architecture\n",
    "def fast_train(arch, epochs=None, device='cuda', subset_size=10000):\n",
    "    return original_train(arch, epochs=EVAL_EPOCHS, device=device, subset_size=subset_size)\n",
    "evaluation.train_architecture = fast_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Initialize Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üì¶ Initializing DQN agent...\")\n",
    "agent = CreativityDQN(device=device)\n",
    "print(\"‚úÖ Agent ready!\")\n",
    "print(f\"   Q-Network parameters: {sum(p.numel() for p in agent.q_network.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Train Agent\n",
    "\n",
    "This will take a few minutes. Watch the progress bar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nüé¨ Starting training for {EPISODES} episodes...\\n\")\n",
    "\n",
    "best_archs, stats = agent.train(num_episodes=EPISODES, update_freq=5, eval_freq=25)\n",
    "\n",
    "print(f\"\\n‚úÖ Training complete!\")\n",
    "print(f\"   Found {len(best_archs)} interesting architectures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Training Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Episode rewards\n",
    "axes[0].plot(stats['episode_rewards'])\n",
    "axes[0].set_title('Episode Rewards')\n",
    "axes[0].set_xlabel('Episode')\n",
    "axes[0].set_ylabel('Reward')\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Epsilon decay\n",
    "axes[1].plot(stats['epsilons'])\n",
    "axes[1].set_title('Exploration (Epsilon)')\n",
    "axes[1].set_xlabel('Episode')\n",
    "axes[1].set_ylabel('Epsilon')\n",
    "axes[1].grid(True)\n",
    "\n",
    "# Reward distribution\n",
    "axes[2].hist(stats['episode_rewards'], bins=30)\n",
    "axes[2].set_title('Reward Distribution')\n",
    "axes[2].set_xlabel('Reward')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average reward: {sum(stats['episode_rewards'])/len(stats['episode_rewards']):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Final Evaluation\n",
    "\n",
    "Now we'll fully train the top architectures with more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore original training function for final evaluation\n",
    "evaluation.train_architecture = original_train\n",
    "\n",
    "print(f\"üéì Evaluating top {TOP_K} architectures...\\n\")\n",
    "\n",
    "final_results = []\n",
    "for i, arch_data in enumerate(best_archs[:TOP_K]):\n",
    "    arch = arch_data['architecture']\n",
    "    print(f\"[{i+1}/{TOP_K}] Nodes: {len(arch.nodes)}, Depth: {arch.depth}, Width: {arch.avg_width:.1f}\")\n",
    "    \n",
    "    final_acc = original_train(\n",
    "        arch,\n",
    "        epochs=10,\n",
    "        device=device,\n",
    "        subset_size=None\n",
    "    )\n",
    "    \n",
    "    print(f\"    ‚úÖ Accuracy: {final_acc:.4f}\\n\")\n",
    "    \n",
    "    final_results.append({\n",
    "        'architecture': arch,\n",
    "        'search_reward': arch_data['reward'],\n",
    "        'final_accuracy': final_acc,\n",
    "        'trajectory': arch_data.get('trajectory', [])\n",
    "    })\n",
    "\n",
    "print(\"‚úÖ Evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"üíæ Saving results...\\n\")\n",
    "save_all_results(OUTPUT_DIR, best_archs, final_results, stats, DATASET)\n",
    "\n",
    "print(\"\\nüìä Creating visualizations...\")\n",
    "create_results_report(OUTPUT_DIR)\n",
    "\n",
    "print(f\"\\n‚úÖ All results saved to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÜ Best Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = max(final_results, key=lambda x: x['final_accuracy'])\n",
    "best_arch = best['architecture']\n",
    "\n",
    "print(\"üèÜ BEST ARCHITECTURE\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Final Accuracy:  {best['final_accuracy']:.4f}\")\n",
    "print(f\"Search Reward:   {best['search_reward']:.4f}\")\n",
    "print(f\"Nodes:           {len(best_arch.nodes)}\")\n",
    "print(f\"Edges:           {len(best_arch.edges)}\")\n",
    "print(f\"Depth:           {best_arch.depth}\")\n",
    "print(f\"Avg Width:       {best_arch.avg_width:.1f}\")\n",
    "print(f\"Parameters:      {best_arch.total_params:,}\")\n",
    "print(f\"Skip Connections: {best_arch.num_skip_connections}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Visualize best architecture\n",
    "viz_path = os.path.join(OUTPUT_DIR, 'best_architecture.png')\n",
    "visualize_architecture(best_arch, save_path=viz_path, \n",
    "                      title=f\"Best Architecture (Acc: {best['final_accuracy']:.4f})\")\n",
    "\n",
    "from IPython.display import Image, display\n",
    "display(Image(filename=viz_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Top 10 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create results table\n",
    "results_data = []\n",
    "for i, result in enumerate(sorted(final_results, key=lambda x: x['final_accuracy'], reverse=True)[:10]):\n",
    "    arch = result['architecture']\n",
    "    results_data.append({\n",
    "        'Rank': i+1,\n",
    "        'Accuracy': f\"{result['final_accuracy']:.4f}\",\n",
    "        'Reward': f\"{result['search_reward']:.3f}\",\n",
    "        'Nodes': len(arch.nodes),\n",
    "        'Depth': arch.depth,\n",
    "        'Avg Width': f\"{arch.avg_width:.1f}\",\n",
    "        'Parameters': f\"{arch.total_params:,}\"\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results_data)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® Visualize Top 5 Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "viz_dir = os.path.join(OUTPUT_DIR, 'visualizations')\n",
    "\n",
    "top_5 = sorted(final_results, key=lambda x: x['final_accuracy'], reverse=True)[:5]\n",
    "\n",
    "for i, result in enumerate(top_5):\n",
    "    arch = result['architecture']\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Rank #{i+1} - Accuracy: {result['final_accuracy']:.4f}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Find corresponding visualization\n",
    "    import json\n",
    "    results_file = os.path.join(OUTPUT_DIR, 'results.jsonl')\n",
    "    with open(results_file) as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            if abs(data['final_accuracy'] - result['final_accuracy']) < 0.0001:\n",
    "                arch_id = data['arch_id']\n",
    "                img_path = os.path.join(viz_dir, f\"{arch_id}.png\")\n",
    "                if os.path.exists(img_path):\n",
    "                    display(Image(filename=img_path, width=600))\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ View Full Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_path = os.path.join(OUTPUT_DIR, 'report.html')\n",
    "\n",
    "print(f\"üìä Full interactive report available at:\")\n",
    "print(f\"   {report_path}\")\n",
    "print(f\"\\nüìÅ All files saved to:\")\n",
    "print(f\"   {OUTPUT_DIR}\")\n",
    "print(f\"\\nüì¶ Includes:\")\n",
    "print(f\"   - PyTorch models (.pth): {OUTPUT_DIR}/models/\")\n",
    "print(f\"   - Architecture JSON: {OUTPUT_DIR}/architectures/\")\n",
    "print(f\"   - Visualizations: {OUTPUT_DIR}/visualizations/\")\n",
    "print(f\"   - Results: {OUTPUT_DIR}/results.jsonl\")\n",
    "\n",
    "# Display link to report\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(f'<a href=\"{report_path}\" target=\"_blank\">üîó Open Full Report</a>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Load & Explore Saved Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load a specific architecture\n",
    "arch_dir = os.path.join(OUTPUT_DIR, 'architectures')\n",
    "arch_files = sorted([f for f in os.listdir(arch_dir) if f.endswith('.json')])\n",
    "\n",
    "if arch_files:\n",
    "    # Load first architecture\n",
    "    arch_path = os.path.join(arch_dir, arch_files[0])\n",
    "    loaded_arch = load_architecture_json(arch_path)\n",
    "    \n",
    "    print(f\"Loaded: {arch_files[0]}\")\n",
    "    print(f\"  Nodes: {len(loaded_arch.nodes)}\")\n",
    "    print(f\"  Edges: {len(loaded_arch.edges)}\")\n",
    "    print(f\"  Depth: {loaded_arch.depth}\")\n",
    "    print(f\"  Operations: {list(set(loaded_arch.operations.values()))}\")\n",
    "    \n",
    "    # Can create a model from it\n",
    "    model = ConvNet(loaded_arch, num_classes=10)\n",
    "    print(f\"\\n  Model created with {sum(p.numel() for p in model.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Demo Complete!\n",
    "\n",
    "### What you got:\n",
    "- ‚úÖ Trained DQN agent\n",
    "- ‚úÖ Top architectures discovered\n",
    "- ‚úÖ Models saved as .pth files\n",
    "- ‚úÖ Architectures saved as .json files\n",
    "- ‚úÖ Interactive HTML report\n",
    "- ‚úÖ Visualizations of all architectures\n",
    "\n",
    "### Next steps:\n",
    "1. Open the HTML report to explore all results\n",
    "2. Load saved models and use them for inference\n",
    "3. Run again with different settings for better results\n",
    "4. Use `train.py` for longer training runs\n",
    "\n",
    "**Happy Architecture Hunting! üé®‚ú®**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
