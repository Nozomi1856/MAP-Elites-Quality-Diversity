{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ¨ MAP-Elites Creative Architecture Search - Demo\n",
    "\n",
    "MAP-Elites is a **Quality-Diversity** algorithm that discovers diverse, high-quality architectures.\n",
    "\n",
    "**Key advantages:**\n",
    "- âœ… Guaranteed diversity across behavior space\n",
    "- âœ… No neural networks in search (faster!)\n",
    "- âœ… Simpler than Deep RL\n",
    "- âœ… More reliable and predictable\n",
    "- âœ… Systematic coverage of design space\n",
    "\n",
    "**Estimated time:** 3-10 minutes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if needed\n",
    "# !pip install torch torchvision torch-geometric networkx scipy matplotlib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from datetime import datetime\n",
    "from IPython.display import display, HTML, Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"ðŸ–¥ï¸  Using device: {device}\")\n",
    "if device == 'cpu':\n",
    "    print(\"âš ï¸  No GPU detected. Recommend MNIST with fewer iterations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== MAP-ELITES CONFIGURATION =====\n",
    "\n",
    "# Dataset: 'mnist', 'fashion', 'cifar10'\n",
    "DATASET = 'mnist'\n",
    "\n",
    "# Number of iterations\n",
    "ITERATIONS = 200\n",
    "\n",
    "# Behavior space resolution (depth_bins, width_bins, skip_bins)\n",
    "# Low: (3, 3, 3) = 27 cells\n",
    "# Medium: (5, 5, 4) = 100 cells\n",
    "# High: (7, 7, 5) = 245 cells\n",
    "DEPTH_BINS = 5\n",
    "WIDTH_BINS = 5\n",
    "SKIP_BINS = 4\n",
    "\n",
    "# Number of top architectures to evaluate\n",
    "TOP_K = 10\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = f'demo_results_mapelites/{DATASET}_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "\n",
    "print(\"ðŸ“‹ Configuration:\")\n",
    "print(f\"  Algorithm: MAP-Elites (Quality-Diversity)\")\n",
    "print(f\"  Dataset: {DATASET}\")\n",
    "print(f\"  Iterations: {ITERATIONS}\")\n",
    "print(f\"  Behavior Space: {DEPTH_BINS}Ã—{WIDTH_BINS}Ã—{SKIP_BINS} = {DEPTH_BINS*WIDTH_BINS*SKIP_BINS} cells\")\n",
    "print(f\"  Top K: {TOP_K}\")\n",
    "print(f\"  Output: {OUTPUT_DIR}\")\n",
    "\n",
    "# Time estimate\n",
    "time_estimates = {\n",
    "    'mnist': ITERATIONS * 0.015 + TOP_K * 0.15,\n",
    "    'fashion': ITERATIONS * 0.02 + TOP_K * 0.2,\n",
    "    'cifar10': ITERATIONS * 0.03 + TOP_K * 0.4\n",
    "}\n",
    "print(f\"\\nâ±ï¸  Estimated time: ~{time_estimates[DATASET]:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ—ï¸ Load Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from map_elites import MAPElites, BehaviorSpace, MutationOperator, QualityDiversityArchive\n",
    "from architecture import ArchitectureState, OPERATION_POOL\n",
    "from evaluation import ConvNet, train_architecture\n",
    "from utils import save_all_results, load_architecture_json\n",
    "from visualize import visualize_architecture, create_results_report\n",
    "\n",
    "print(\"âœ… All modules loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”§ Configure Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluation\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "\n",
    "if DATASET == 'mnist':\n",
    "    def get_mnist_loaders(batch_size=128, subset_size=None):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(32),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "            transforms.Normalize((0.1307,)*3, (0.3081,)*3)\n",
    "        ])\n",
    "        \n",
    "        trainset = torchvision.datasets.MNIST(\n",
    "            root='./data', train=True, download=True, transform=transform\n",
    "        )\n",
    "        testset = torchvision.datasets.MNIST(\n",
    "            root='./data', train=False, download=True, transform=transform\n",
    "        )\n",
    "        \n",
    "        if subset_size:\n",
    "            indices = np.random.choice(len(trainset), subset_size, replace=False)\n",
    "            trainset = Subset(trainset, indices)\n",
    "        \n",
    "        return (DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2),\n",
    "               DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2))\n",
    "    \n",
    "    evaluation.get_cifar10_loaders = get_mnist_loaders\n",
    "    print(\"ðŸ“Š Dataset: MNIST\")\n",
    "\n",
    "elif DATASET == 'fashion':\n",
    "    def get_fashion_loaders(batch_size=128, subset_size=None):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(32),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "            transforms.Normalize((0.2860,)*3, (0.3530,)*3)\n",
    "        ])\n",
    "        \n",
    "        trainset = torchvision.datasets.FashionMNIST(\n",
    "            root='./data', train=True, download=True, transform=transform\n",
    "        )\n",
    "        testset = torchvision.datasets.FashionMNIST(\n",
    "            root='./data', train=False, download=True, transform=transform\n",
    "        )\n",
    "        \n",
    "        if subset_size:\n",
    "            indices = np.random.choice(len(trainset), subset_size, replace=False)\n",
    "            trainset = Subset(trainset, indices)\n",
    "        \n",
    "        return (DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2),\n",
    "               DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2))\n",
    "    \n",
    "    evaluation.get_cifar10_loaders = get_fashion_loaders\n",
    "    print(\"ðŸ“Š Dataset: Fashion-MNIST\")\n",
    "\n",
    "else:\n",
    "    print(\"ðŸ“Š Dataset: CIFAR-10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Initialize MAP-Elites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“¦ Initializing MAP-Elites...\")\n",
    "\n",
    "# Define behavior space\n",
    "behavior_space = BehaviorSpace(\n",
    "    depth_bins=DEPTH_BINS,\n",
    "    width_bins=WIDTH_BINS,\n",
    "    skip_bins=SKIP_BINS\n",
    ")\n",
    "\n",
    "# Define mutation operator\n",
    "mutation_operator = MutationOperator()\n",
    "\n",
    "# Initialize MAP-Elites\n",
    "map_elites = MAPElites(\n",
    "    behavior_space=behavior_space,\n",
    "    mutation_operator=mutation_operator,\n",
    "    operation_strategy='diverse'\n",
    ")\n",
    "\n",
    "print(f\"âœ… MAP-Elites initialized\")\n",
    "print(f\"   Total cells: {behavior_space.get_total_cells()}\")\n",
    "print(f\"   Mutation types: {len(mutation_operator.mutation_types)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ Run MAP-Elites\n",
    "\n",
    "Watch the coverage increase as diverse architectures are discovered!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation function\n",
    "def evaluate_architecture(arch: ArchitectureState) -> float:\n",
    "    \"\"\"Quick evaluation during search\"\"\"\n",
    "    try:\n",
    "        accuracy = train_architecture(\n",
    "            arch,\n",
    "            epochs=3,\n",
    "            device=device,\n",
    "            subset_size=10000\n",
    "        )\n",
    "        return accuracy\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return 0.1\n",
    "\n",
    "print(f\"ðŸŽ¯ Running MAP-Elites for {ITERATIONS} iterations...\\n\")\n",
    "\n",
    "archive = map_elites.run(\n",
    "    num_iterations=ITERATIONS,\n",
    "    evaluate_fn=evaluate_architecture,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… MAP-Elites complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = archive.get_stats()\n",
    "\n",
    "print(\"ðŸ“‹ MAP-Elites Statistics\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Coverage:        {stats['coverage']:.2%}\")\n",
    "print(f\"Cells filled:    {stats['num_filled']}/{behavior_space.get_total_cells()}\")\n",
    "print(f\"Best performance: {stats['best_performance']:.4f}\")\n",
    "print(f\"Mean performance: {stats['mean_performance']:.4f}\")\n",
    "print(f\"Total evaluated:  {stats['total_evaluated']}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Visualize Behavior Space Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get all behaviors and performances\n",
    "all_archs = archive.get_all_architectures()\n",
    "behaviors = [b for _, _, b in all_archs]\n",
    "performances = [p for _, p, _ in all_archs]\n",
    "\n",
    "# Create 2D heatmap (depth vs width)\n",
    "heatmap = np.zeros((DEPTH_BINS, WIDTH_BINS))\n",
    "counts = np.zeros((DEPTH_BINS, WIDTH_BINS))\n",
    "\n",
    "for (d, w, s), perf in zip(behaviors, performances):\n",
    "    heatmap[d, w] += perf\n",
    "    counts[d, w] += 1\n",
    "\n",
    "# Average performance per cell\n",
    "heatmap = np.divide(heatmap, counts, where=counts>0, out=np.zeros_like(heatmap))\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Coverage heatmap\n",
    "im1 = axes[0].imshow((counts > 0).astype(int), cmap='Blues', aspect='auto')\n",
    "axes[0].set_title('Coverage (Depth vs Width)')\n",
    "axes[0].set_xlabel('Width Bin')\n",
    "axes[0].set_ylabel('Depth Bin')\n",
    "plt.colorbar(im1, ax=axes[0], label='Filled')\n",
    "\n",
    "# Performance heatmap\n",
    "im2 = axes[1].imshow(heatmap, cmap='viridis', aspect='auto')\n",
    "axes[1].set_title('Average Performance (Depth vs Width)')\n",
    "axes[1].set_xlabel('Width Bin')\n",
    "axes[1].set_ylabel('Depth Bin')\n",
    "plt.colorbar(im2, ax=axes[1], label='Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nðŸ“Š Coverage: {stats['coverage']:.2%} of behavior space explored\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ“ Final Evaluation\n",
    "\n",
    "Fully train the top architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Evaluating top {TOP_K} architectures...\\n\")\n",
    "\n",
    "all_archs = archive.get_all_architectures()\n",
    "all_archs.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "final_results = []\n",
    "\n",
    "for i, (arch, search_perf, behavior) in enumerate(all_archs[:TOP_K]):\n",
    "    print(f\"[{i+1}/{TOP_K}] Behavior: depth={behavior[0]}, width={behavior[1]}, skip={behavior[2]}\")\n",
    "    \n",
    "    final_acc = train_architecture(\n",
    "        arch,\n",
    "        epochs=10,\n",
    "        device=device,\n",
    "        subset_size=None\n",
    "    )\n",
    "    \n",
    "    print(f\"    âœ… Accuracy: {final_acc:.4f}\\n\")\n",
    "    \n",
    "    final_results.append({\n",
    "        'architecture': arch,\n",
    "        'search_reward': search_perf,\n",
    "        'final_accuracy': final_acc,\n",
    "        'trajectory': [],\n",
    "        'behavior': behavior\n",
    "    })\n",
    "\n",
    "print(\"âœ… Evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Prepare data for saving\n",
    "best_archs = [{\n",
    "    'architecture': item['architecture'],\n",
    "    'reward': item['performance'],\n",
    "    'trajectory': [],\n",
    "    'episode': 0\n",
    "} for item in archive.history]\n",
    "\n",
    "dummy_stats = {\n",
    "    'episode_rewards': [item['performance'] for item in archive.history],\n",
    "    'losses': [],\n",
    "    'epsilons': []\n",
    "}\n",
    "\n",
    "print(\"ðŸ’¾ Saving results...\\n\")\n",
    "save_all_results(OUTPUT_DIR, best_archs, final_results, dummy_stats, DATASET)\n",
    "\n",
    "print(\"\\nðŸ“Š Creating visualizations...\")\n",
    "create_results_report(OUTPUT_DIR)\n",
    "\n",
    "print(f\"\\nâœ… All results saved to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ† Best Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = max(final_results, key=lambda x: x['final_accuracy'])\n",
    "best_arch = best['architecture']\n",
    "\n",
    "print(\"ðŸ† BEST ARCHITECTURE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Accuracy:  {best['final_accuracy']:.4f}\")\n",
    "print(f\"Behavior:  {best['behavior']}\")\n",
    "print(f\"Nodes:     {len(best_arch.nodes)}\")\n",
    "print(f\"Edges:     {len(best_arch.edges)}\")\n",
    "print(f\"Depth:     {best_arch.depth}\")\n",
    "print(f\"Avg Width: {best_arch.avg_width:.1f}\")\n",
    "print(f\"Parameters: {best_arch.total_params:,}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Visualize\n",
    "viz_path = os.path.join(OUTPUT_DIR, 'best_architecture.png')\n",
    "visualize_architecture(best_arch, save_path=viz_path,\n",
    "                      title=f\"Best: Acc={best['final_accuracy']:.4f}, Behavior={best['behavior']}\")\n",
    "display(Image(filename=viz_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Top 10 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_data = []\n",
    "for i, result in enumerate(sorted(final_results, key=lambda x: x['final_accuracy'], reverse=True)[:10]):\n",
    "    arch = result['architecture']\n",
    "    behavior = result['behavior']\n",
    "    results_data.append({\n",
    "        'Rank': i+1,\n",
    "        'Accuracy': f\"{result['final_accuracy']:.4f}\",\n",
    "        'Behavior (D,W,S)': f\"({behavior[0]},{behavior[1]},{behavior[2]})\",\n",
    "        'Nodes': len(arch.nodes),\n",
    "        'Depth': arch.depth,\n",
    "        'Avg Width': f\"{arch.avg_width:.1f}\",\n",
    "        'Parameters': f\"{arch.total_params:,}\"\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results_data)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¨ Diversity Showcase\n",
    "\n",
    "Show architectures from different behavior cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select diverse architectures\n",
    "diverse_archs = []\n",
    "seen_behaviors = set()\n",
    "\n",
    "for arch, perf, behavior in sorted(all_archs, key=lambda x: x[1], reverse=True):\n",
    "    if behavior not in seen_behaviors:\n",
    "        diverse_archs.append((arch, perf, behavior))\n",
    "        seen_behaviors.add(behavior)\n",
    "    \n",
    "    if len(diverse_archs) >= 5:\n",
    "        break\n",
    "\n",
    "print(\"ðŸŽ¨ Diverse Architectures from Different Cells:\\n\")\n",
    "\n",
    "for i, (arch, perf, behavior) in enumerate(diverse_archs):\n",
    "    print(f\"Architecture {i+1}:\")\n",
    "    print(f\"  Behavior: depth={behavior[0]}, width={behavior[1]}, skip={behavior[2]}\")\n",
    "    print(f\"  Performance: {perf:.4f}\")\n",
    "    print(f\"  Depth: {arch.depth}, Width: {arch.avg_width:.1f}, Nodes: {len(arch.nodes)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Demo Complete!\n",
    "\n",
    "### What you got:\n",
    "- âœ… Diverse architecture portfolio\n",
    "- âœ… Coverage across behavior space\n",
    "- âœ… Models saved as .pth files\n",
    "- âœ… Architectures saved as .json files\n",
    "- âœ… Interactive HTML report\n",
    "\n",
    "### Key advantages of MAP-Elites:\n",
    "1. **Guaranteed diversity** - Systematic coverage\n",
    "2. **No collapse** - Can't converge to single solution\n",
    "3. **Simpler** - No neural networks in search\n",
    "4. **Faster** - Less computation per iteration\n",
    "5. **More reliable** - Deterministic behavior\n",
    "\n",
    "**Open `report.html` to explore all results!** ðŸŽ‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
