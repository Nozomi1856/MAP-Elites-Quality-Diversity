{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé® MAP-Elites NAS - Self-Contained Notebook\n",
    "\n",
    "**Everything in one notebook - no external files needed!**\n",
    "\n",
    "This notebook contains all the code you need. Just run the cells in order.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this once to install packages\n",
    "!pip install torch torchvision networkx matplotlib tqdm scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Section 1: Architecture Classes\n",
    "\n",
    "This section defines how we represent neural architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "import networkx as nx\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "# Operation pool\n",
    "OPERATION_POOL = [\n",
    "    'conv3x3',\n",
    "    'conv5x5',\n",
    "    'sep_conv3x3',\n",
    "    'sep_conv5x5',\n",
    "    'max_pool3x3',\n",
    "    'avg_pool3x3',\n",
    "    'skip_connect'\n",
    "]\n",
    "\n",
    "OP_TO_IDX = {op: idx for idx, op in enumerate(OPERATION_POOL)}\n",
    "\n",
    "\n",
    "class ArchitectureState:\n",
    "    \"\"\"Represents a neural network architecture as a directed acyclic graph.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.nodes = []\n",
    "        self.edges = []\n",
    "        self.operations = {}\n",
    "        self.channels = {}\n",
    "        self.positions = {}\n",
    "        self.input_node = None\n",
    "        self.output_node = None\n",
    "        self._node_counter = 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def initialize_starter(operation_strategy='diverse'):\n",
    "        \"\"\"Create a simple starter architecture.\"\"\"\n",
    "        arch = ArchitectureState()\n",
    "        \n",
    "        # Input node\n",
    "        arch.input_node = arch.add_node('input', 3, 0)\n",
    "        \n",
    "        # Hidden layers\n",
    "        node1 = arch.add_node('conv3x3', 32, 1)\n",
    "        node2 = arch.add_node('conv3x3', 64, 2)\n",
    "        \n",
    "        # Output node\n",
    "        arch.output_node = arch.add_node('output', 10, 3)\n",
    "        \n",
    "        # Edges\n",
    "        arch.add_edge(arch.input_node, node1)\n",
    "        arch.add_edge(node1, node2)\n",
    "        arch.add_edge(node2, arch.output_node)\n",
    "        \n",
    "        return arch\n",
    "    \n",
    "    def add_node(self, operation: str, channels: int, position: int) -> int:\n",
    "        \"\"\"Add a node to the architecture.\"\"\"\n",
    "        node_id = self._node_counter\n",
    "        self._node_counter += 1\n",
    "        \n",
    "        self.nodes.append(node_id)\n",
    "        self.operations[node_id] = operation\n",
    "        self.channels[node_id] = channels\n",
    "        self.positions[node_id] = position\n",
    "        \n",
    "        return node_id\n",
    "    \n",
    "    def add_edge(self, src: int, dst: int):\n",
    "        \"\"\"Add an edge between nodes.\"\"\"\n",
    "        if (src, dst) not in self.edges:\n",
    "            self.edges.append((src, dst))\n",
    "    \n",
    "    def remove_node(self, node_id: int):\n",
    "        \"\"\"Remove a node and reconnect.\"\"\"\n",
    "        if node_id in [self.input_node, self.output_node]:\n",
    "            return\n",
    "        \n",
    "        # Get predecessors and successors\n",
    "        predecessors = [src for src, dst in self.edges if dst == node_id]\n",
    "        successors = [dst for src, dst in self.edges if src == node_id]\n",
    "        \n",
    "        # Remove edges\n",
    "        self.edges = [(src, dst) for src, dst in self.edges \n",
    "                     if src != node_id and dst != node_id]\n",
    "        \n",
    "        # Reconnect\n",
    "        for pred in predecessors:\n",
    "            for succ in successors:\n",
    "                self.add_edge(pred, succ)\n",
    "        \n",
    "        # Remove node\n",
    "        self.nodes.remove(node_id)\n",
    "        del self.operations[node_id]\n",
    "        del self.channels[node_id]\n",
    "        del self.positions[node_id]\n",
    "    \n",
    "    def remove_edge(self, src: int, dst: int):\n",
    "        \"\"\"Remove an edge.\"\"\"\n",
    "        if (src, dst) in self.edges:\n",
    "            self.edges.remove((src, dst))\n",
    "    \n",
    "    def increase_channels(self, node_id: int):\n",
    "        \"\"\"Double channels at a node.\"\"\"\n",
    "        self.channels[node_id] = min(self.channels[node_id] * 2, 512)\n",
    "    \n",
    "    def decrease_channels(self, node_id: int):\n",
    "        \"\"\"Halve channels at a node.\"\"\"\n",
    "        self.channels[node_id] = max(self.channels[node_id] // 2, 16)\n",
    "    \n",
    "    def copy(self):\n",
    "        \"\"\"Create a deep copy.\"\"\"\n",
    "        return copy.deepcopy(self)\n",
    "    \n",
    "    @property\n",
    "    def depth(self) -> int:\n",
    "        \"\"\"Maximum depth of the architecture.\"\"\"\n",
    "        if not self.positions:\n",
    "            return 0\n",
    "        return max(self.positions.values()) - min(self.positions.values())\n",
    "    \n",
    "    @property\n",
    "    def avg_width(self) -> float:\n",
    "        \"\"\"Average number of channels.\"\"\"\n",
    "        if not self.channels:\n",
    "            return 0\n",
    "        return sum(self.channels.values()) / len(self.channels)\n",
    "    \n",
    "    @property\n",
    "    def total_params(self) -> int:\n",
    "        \"\"\"Estimate total parameters.\"\"\"\n",
    "        params = 0\n",
    "        for src, dst in self.edges:\n",
    "            params += self.channels[src] * self.channels[dst] * 9  # 3x3 conv\n",
    "        return params\n",
    "    \n",
    "    @property\n",
    "    def num_skip_connections(self) -> int:\n",
    "        \"\"\"Count skip connections.\"\"\"\n",
    "        count = 0\n",
    "        for src, dst in self.edges:\n",
    "            if self.positions[dst] - self.positions[src] > 1:\n",
    "                count += 1\n",
    "        return count\n",
    "\n",
    "print(\"‚úÖ Architecture classes loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Section 2: Neural Network Model\n",
    "\n",
    "Convert architecture to executable PyTorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    \"\"\"Convert ArchitectureState to executable PyTorch model.\"\"\"\n",
    "    \n",
    "    def __init__(self, arch: ArchitectureState, num_classes: int = 10):\n",
    "        super().__init__()\n",
    "        self.arch = arch\n",
    "        self.num_classes = num_classes\n",
    "        self.layers = nn.ModuleDict()\n",
    "        \n",
    "        # Create layers\n",
    "        for node in arch.nodes:\n",
    "            if node == arch.input_node:\n",
    "                continue\n",
    "            \n",
    "            op = arch.operations[node]\n",
    "            in_channels = self._get_input_channels(node)\n",
    "            out_channels = arch.channels[node]\n",
    "            \n",
    "            if node == arch.output_node:\n",
    "                self.layers[str(node)] = nn.Linear(in_channels, num_classes)\n",
    "            else:\n",
    "                self.layers[str(node)] = self._create_operation(op, in_channels, out_channels)\n",
    "    \n",
    "    def _get_input_channels(self, node: int) -> int:\n",
    "        \"\"\"Get input channels for a node.\"\"\"\n",
    "        predecessors = [src for src, dst in self.arch.edges if dst == node]\n",
    "        if not predecessors:\n",
    "            return 3\n",
    "        return sum(self.arch.channels[pred] for pred in predecessors)\n",
    "    \n",
    "    def _create_operation(self, op: str, in_channels: int, out_channels: int):\n",
    "        \"\"\"Create operation layer.\"\"\"\n",
    "        if op == 'conv3x3':\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        elif op == 'conv5x5':\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 5, padding=2),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        elif op == 'max_pool3x3':\n",
    "            return nn.Sequential(\n",
    "                nn.MaxPool2d(3, stride=1, padding=1),\n",
    "                nn.Conv2d(in_channels, out_channels, 1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        elif op == 'skip_connect':\n",
    "            if in_channels == out_channels:\n",
    "                return nn.Identity()\n",
    "            else:\n",
    "                return nn.Conv2d(in_channels, out_channels, 1)\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        outputs = {self.arch.input_node: x}\n",
    "        \n",
    "        # Topological sort\n",
    "        sorted_nodes = self._topological_sort()\n",
    "        \n",
    "        for node in sorted_nodes:\n",
    "            if node == self.arch.input_node:\n",
    "                continue\n",
    "            \n",
    "            # Get inputs\n",
    "            predecessors = [src for src, dst in self.arch.edges if dst == node]\n",
    "            if not predecessors:\n",
    "                continue\n",
    "            \n",
    "            # Concatenate inputs\n",
    "            inputs = [outputs[pred] for pred in predecessors if pred in outputs]\n",
    "            if not inputs:\n",
    "                continue\n",
    "            \n",
    "            x = torch.cat(inputs, dim=1) if len(inputs) > 1 else inputs[0]\n",
    "            \n",
    "            # Apply operation\n",
    "            if node == self.arch.output_node:\n",
    "                x = F.adaptive_avg_pool2d(x, 1)\n",
    "                x = x.flatten(1)\n",
    "                outputs[node] = self.layers[str(node)](x)\n",
    "            else:\n",
    "                outputs[node] = self.layers[str(node)](x)\n",
    "        \n",
    "        return outputs[self.arch.output_node]\n",
    "    \n",
    "    def _topological_sort(self) -> List[int]:\n",
    "        \"\"\"Sort nodes topologically.\"\"\"\n",
    "        return sorted(self.arch.nodes, key=lambda n: self.arch.positions[n])\n",
    "\n",
    "print(\"‚úÖ ConvNet model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Section 3: Training Function\n",
    "\n",
    "Train and evaluate architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "\n",
    "def get_data_loaders(dataset='mnist', batch_size=128, subset_size=None):\n",
    "    \"\"\"Get data loaders for training.\"\"\"\n",
    "    if dataset == 'mnist':\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(32),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "            transforms.Normalize((0.1307,)*3, (0.3081,)*3)\n",
    "        ])\n",
    "        trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "        testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "    \n",
    "    elif dataset == 'fashion':\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(32),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "            transforms.Normalize((0.2860,)*3, (0.3530,)*3)\n",
    "        ])\n",
    "        trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "        testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "    \n",
    "    else:  # cifar10\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "        ])\n",
    "        trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "        testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "    \n",
    "    if subset_size:\n",
    "        indices = np.random.choice(len(trainset), subset_size, replace=False)\n",
    "        trainset = Subset(trainset, indices)\n",
    "    \n",
    "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    \n",
    "    return trainloader, testloader\n",
    "\n",
    "\n",
    "def train_architecture(arch: ArchitectureState, \n",
    "                      epochs: int = 3,\n",
    "                      device: str = 'cuda',\n",
    "                      dataset: str = 'mnist',\n",
    "                      subset_size: int = 10000) -> float:\n",
    "    \"\"\"Train an architecture and return accuracy.\"\"\"\n",
    "    try:\n",
    "        # Create model\n",
    "        model = ConvNet(arch, num_classes=10).to(device)\n",
    "        \n",
    "        # Get data\n",
    "        trainloader, testloader = get_data_loaders(dataset, subset_size=subset_size)\n",
    "        \n",
    "        # Training setup\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "        \n",
    "        # Train\n",
    "        model.train()\n",
    "        for epoch in range(epochs):\n",
    "            for inputs, labels in trainloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Evaluate\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in testloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        accuracy = correct / total\n",
    "        return accuracy\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error training: {e}\")\n",
    "        return 0.1\n",
    "\n",
    "print(\"‚úÖ Training function loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß¨ Section 4: MAP-Elites Algorithm\n",
    "\n",
    "Quality-Diversity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "class BehaviorSpace:\n",
    "    \"\"\"Defines behavior dimensions for MAP-Elites.\"\"\"\n",
    "    \n",
    "    def __init__(self, depth_bins=5, width_bins=5, skip_bins=4):\n",
    "        self.depth_bins = depth_bins\n",
    "        self.width_bins = width_bins\n",
    "        self.skip_bins = skip_bins\n",
    "        \n",
    "        self.depth_range = (3, 20)\n",
    "        self.width_range = (16, 256)\n",
    "        self.skip_range = (0.0, 1.0)\n",
    "    \n",
    "    def get_behavior(self, arch: ArchitectureState) -> Tuple[int, int, int]:\n",
    "        \"\"\"Get behavior descriptor for architecture.\"\"\"\n",
    "        depth = arch.depth\n",
    "        depth_bin = self._discretize(depth, self.depth_range, self.depth_bins)\n",
    "        \n",
    "        avg_width = arch.avg_width\n",
    "        width_bin = self._discretize(avg_width, self.width_range, self.width_bins)\n",
    "        \n",
    "        num_possible_skips = len(arch.nodes) * (len(arch.nodes) - 1) / 2\n",
    "        skip_ratio = arch.num_skip_connections / (num_possible_skips + 1e-6)\n",
    "        skip_bin = self._discretize(skip_ratio, self.skip_range, self.skip_bins)\n",
    "        \n",
    "        return (depth_bin, width_bin, skip_bin)\n",
    "    \n",
    "    def _discretize(self, value: float, value_range: Tuple[float, float], num_bins: int) -> int:\n",
    "        \"\"\"Discretize value into bin.\"\"\"\n",
    "        min_val, max_val = value_range\n",
    "        value = np.clip(value, min_val, max_val)\n",
    "        normalized = (value - min_val) / (max_val - min_val + 1e-6)\n",
    "        bin_idx = int(normalized * num_bins)\n",
    "        return min(bin_idx, num_bins - 1)\n",
    "    \n",
    "    def get_total_cells(self) -> int:\n",
    "        return self.depth_bins * self.width_bins * self.skip_bins\n",
    "\n",
    "\n",
    "class MutationOperator:\n",
    "    \"\"\"Defines mutation operations.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.mutation_types = [\n",
    "            'add_node', 'remove_node', 'add_edge', 'remove_edge',\n",
    "            'increase_channels', 'decrease_channels', 'replace_operation'\n",
    "        ]\n",
    "    \n",
    "    def mutate(self, arch: ArchitectureState, operation_strategy='diverse') -> ArchitectureState:\n",
    "        \"\"\"Apply random mutation.\"\"\"\n",
    "        new_arch = arch.copy()\n",
    "        mutation = random.choice(self.mutation_types)\n",
    "        \n",
    "        try:\n",
    "            if mutation == 'add_node':\n",
    "                self._add_node(new_arch, operation_strategy)\n",
    "            elif mutation == 'remove_node':\n",
    "                self._remove_node(new_arch)\n",
    "            elif mutation == 'add_edge':\n",
    "                self._add_edge(new_arch)\n",
    "            elif mutation == 'remove_edge':\n",
    "                self._remove_edge(new_arch)\n",
    "            elif mutation == 'increase_channels':\n",
    "                self._increase_channels(new_arch)\n",
    "            elif mutation == 'decrease_channels':\n",
    "                self._decrease_channels(new_arch)\n",
    "            elif mutation == 'replace_operation':\n",
    "                self._replace_operation(new_arch)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return new_arch\n",
    "    \n",
    "    def _add_node(self, arch, strategy):\n",
    "        if len(arch.nodes) >= 20:\n",
    "            return\n",
    "        operation = random.choice(OPERATION_POOL)\n",
    "        position = random.randint(1, max(arch.positions.values()))\n",
    "        channels = random.choice([32, 64, 128])\n",
    "        new_id = arch.add_node(operation, channels, position)\n",
    "        \n",
    "        # Connect randomly\n",
    "        prev_nodes = [n for n in arch.nodes if arch.positions[n] < position and n != new_id]\n",
    "        next_nodes = [n for n in arch.nodes if arch.positions[n] >= position and n != new_id]\n",
    "        if prev_nodes:\n",
    "            arch.add_edge(random.choice(prev_nodes), new_id)\n",
    "        if next_nodes:\n",
    "            arch.add_edge(new_id, random.choice(next_nodes))\n",
    "    \n",
    "    def _remove_node(self, arch):\n",
    "        removable = [n for n in arch.nodes if n not in [arch.input_node, arch.output_node]]\n",
    "        if removable and len(arch.nodes) > 3:\n",
    "            arch.remove_node(random.choice(removable))\n",
    "    \n",
    "    def _add_edge(self, arch):\n",
    "        possible = [(s, d) for s in arch.nodes for d in arch.nodes \n",
    "                   if s != d and (s, d) not in arch.edges and arch.positions[s] < arch.positions[d]]\n",
    "        if possible:\n",
    "            src, dst = random.choice(possible)\n",
    "            arch.add_edge(src, dst)\n",
    "    \n",
    "    def _remove_edge(self, arch):\n",
    "        if len(arch.edges) > len(arch.nodes):\n",
    "            arch.remove_edge(*random.choice(arch.edges))\n",
    "    \n",
    "    def _increase_channels(self, arch):\n",
    "        node = random.choice([n for n in arch.nodes if arch.channels[n] < 512])\n",
    "        arch.increase_channels(node)\n",
    "    \n",
    "    def _decrease_channels(self, arch):\n",
    "        node = random.choice([n for n in arch.nodes if arch.channels[n] > 16])\n",
    "        arch.decrease_channels(node)\n",
    "    \n",
    "    def _replace_operation(self, arch):\n",
    "        nodes = [n for n in arch.nodes if n not in [arch.input_node, arch.output_node]]\n",
    "        if nodes:\n",
    "            node = random.choice(nodes)\n",
    "            arch.operations[node] = random.choice(OPERATION_POOL)\n",
    "\n",
    "\n",
    "class MAPElites:\n",
    "    \"\"\"MAP-Elites algorithm.\"\"\"\n",
    "    \n",
    "    def __init__(self, behavior_space, mutation_operator, operation_strategy='diverse'):\n",
    "        self.behavior_space = behavior_space\n",
    "        self.mutation_operator = mutation_operator\n",
    "        self.operation_strategy = operation_strategy\n",
    "        self.archive = {}  # behavior -> (arch, performance)\n",
    "        self.history = []\n",
    "    \n",
    "    def initialize(self, num_random=20):\n",
    "        \"\"\"Initialize with random architectures.\"\"\"\n",
    "        for _ in range(num_random):\n",
    "            arch = ArchitectureState.initialize_starter()\n",
    "            for _ in range(random.randint(2, 5)):\n",
    "                arch = self.mutation_operator.mutate(arch)\n",
    "            behavior = self.behavior_space.get_behavior(arch)\n",
    "            self.archive[behavior] = (arch, 0.0)\n",
    "    \n",
    "    def run(self, num_iterations, evaluate_fn, verbose=True):\n",
    "        \"\"\"Run MAP-Elites.\"\"\"\n",
    "        if not self.archive:\n",
    "            self.initialize()\n",
    "        \n",
    "        # Evaluate initial\n",
    "        for behavior, (arch, _) in list(self.archive.items()):\n",
    "            perf = evaluate_fn(arch)\n",
    "            self.archive[behavior] = (arch, perf)\n",
    "        \n",
    "        # Main loop\n",
    "        iterator = tqdm(range(num_iterations)) if verbose else range(num_iterations)\n",
    "        \n",
    "        for i in iterator:\n",
    "            # Sample parent\n",
    "            behavior = random.choice(list(self.archive.keys()))\n",
    "            parent, _ = self.archive[behavior]\n",
    "            \n",
    "            # Mutate\n",
    "            child = self.mutation_operator.mutate(parent)\n",
    "            \n",
    "            # Evaluate\n",
    "            performance = evaluate_fn(child)\n",
    "            \n",
    "            # Get behavior\n",
    "            child_behavior = self.behavior_space.get_behavior(child)\n",
    "            \n",
    "            # Add to archive if better\n",
    "            if child_behavior not in self.archive or performance > self.archive[child_behavior][1]:\n",
    "                self.archive[child_behavior] = (child, performance)\n",
    "            \n",
    "            # Save history\n",
    "            self.history.append({'architecture': child, 'performance': performance, 'behavior': child_behavior})\n",
    "            \n",
    "            # Update progress\n",
    "            if verbose and i % 10 == 0:\n",
    "                coverage = len(self.archive) / self.behavior_space.get_total_cells()\n",
    "                best = max(self.archive.values(), key=lambda x: x[1])[1]\n",
    "                iterator.set_postfix({'coverage': f'{coverage:.2%}', 'best': f'{best:.4f}'})\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def get_stats(self):\n",
    "        \"\"\"Get statistics.\"\"\"\n",
    "        perfs = [p for _, p in self.archive.values()]\n",
    "        return {\n",
    "            'coverage': len(self.archive) / self.behavior_space.get_total_cells(),\n",
    "            'num_filled': len(self.archive),\n",
    "            'best_performance': max(perfs) if perfs else 0,\n",
    "            'mean_performance': np.mean(perfs) if perfs else 0,\n",
    "            'total_evaluated': len(self.history)\n",
    "        }\n",
    "    \n",
    "    def get_all_architectures(self):\n",
    "        \"\"\"Get all architectures.\"\"\"\n",
    "        return [(arch.copy(), perf, behavior) for behavior, (arch, perf) in self.archive.items()]\n",
    "\n",
    "print(\"‚úÖ MAP-Elites loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration\n",
    "\n",
    "Set your parameters here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CONFIGURATION =====\n",
    "\n",
    "DATASET = 'mnist'          # 'mnist', 'fashion', 'cifar10'\n",
    "ITERATIONS = 200           # Number of iterations\n",
    "DEPTH_BINS = 5            # Behavior space resolution\n",
    "WIDTH_BINS = 5\n",
    "SKIP_BINS = 4\n",
    "TOP_K = 10                # Top architectures to evaluate\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Dataset: {DATASET}\")\n",
    "print(f\"  Iterations: {ITERATIONS}\")\n",
    "print(f\"  Behavior space: {DEPTH_BINS}x{WIDTH_BINS}x{SKIP_BINS} = {DEPTH_BINS*WIDTH_BINS*SKIP_BINS} cells\")\n",
    "print(f\"  Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Run MAP-Elites!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "behavior_space = BehaviorSpace(DEPTH_BINS, WIDTH_BINS, SKIP_BINS)\n",
    "mutation_operator = MutationOperator()\n",
    "map_elites = MAPElites(behavior_space, mutation_operator)\n",
    "\n",
    "# Define evaluation\n",
    "def evaluate(arch):\n",
    "    return train_architecture(arch, epochs=3, device=device, dataset=DATASET, subset_size=10000)\n",
    "\n",
    "# Run!\n",
    "print(f\"\\nüéØ Running MAP-Elites...\\n\")\n",
    "map_elites.run(ITERATIONS, evaluate, verbose=True)\n",
    "\n",
    "# Stats\n",
    "stats = map_elites.get_stats()\n",
    "print(f\"\\n‚úÖ Complete!\")\n",
    "print(f\"Coverage: {stats['coverage']:.2%}\")\n",
    "print(f\"Best: {stats['best_performance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all architectures\n",
    "all_archs = map_elites.get_all_architectures()\n",
    "all_archs.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"\\nüèÜ Top {min(TOP_K, len(all_archs))} Architectures:\\n\")\n",
    "\n",
    "for i, (arch, perf, behavior) in enumerate(all_archs[:TOP_K]):\n",
    "    print(f\"{i+1}. Acc: {perf:.4f} | Behavior: {behavior} | Nodes: {len(arch.nodes)} | Depth: {arch.depth}\")\n",
    "\n",
    "# Best\n",
    "best_arch, best_perf, best_behavior = all_archs[0]\n",
    "print(f\"\\nü•á Best Architecture:\")\n",
    "print(f\"   Accuracy: {best_perf:.4f}\")\n",
    "print(f\"   Behavior: {best_behavior}\")\n",
    "print(f\"   Nodes: {len(best_arch.nodes)}\")\n",
    "print(f\"   Depth: {best_arch.depth}\")\n",
    "print(f\"   Avg Width: {best_arch.avg_width:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Done!\n",
    "\n",
    "You've successfully run MAP-Elites! üéâ\n",
    "\n",
    "**Key Results:**\n",
    "- Discovered diverse architectures across behavior space\n",
    "- No external files needed - everything in one notebook!\n",
    "- Simpler and faster than Deep RL approaches\n",
    "\n",
    "**Next steps:**\n",
    "- Increase ITERATIONS for better results\n",
    "- Try different datasets (fashion, cifar10)\n",
    "- Adjust behavior space resolution\n",
    "- Fully train top architectures with more epochs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
