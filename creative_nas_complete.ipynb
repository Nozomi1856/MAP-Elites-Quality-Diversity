{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé® Creative Neural Architecture Search - Complete System\n",
    "\n",
    "This notebook contains the full implementation organized into logical sections.\n",
    "\n",
    "**Use this for:**\n",
    "- Understanding the complete system\n",
    "- Customizing components\n",
    "- Running longer training sessions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Dependencies & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if needed\n",
    "# !pip install torch torchvision torch-geometric networkx scipy matplotlib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, global_max_pool\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import os\n",
    "import json\n",
    "import copy\n",
    "import random\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Architecture Representation\n",
    "\n",
    "Defines how we represent neural architectures as graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed operation pool\n",
    "OPERATION_POOL = [\n",
    "    'conv3x3',\n",
    "    'conv5x5',\n",
    "    'sep_conv3x3',\n",
    "    'sep_conv5x5',\n",
    "    'max_pool3x3',\n",
    "    'avg_pool3x3',\n",
    "    'skip_connect'\n",
    "]\n",
    "\n",
    "OP_TO_IDX = {op: idx for idx, op in enumerate(OPERATION_POOL)}\n",
    "\n",
    "# Action space\n",
    "class ActionSpace:\n",
    "    ADD_NODE = 0\n",
    "    REMOVE_NODE = 1\n",
    "    ADD_EDGE = 2\n",
    "    REMOVE_EDGE = 3\n",
    "    INCREASE_CHANNELS = 4\n",
    "    DECREASE_CHANNELS = 5\n",
    "    STOP_BUILDING = 6\n",
    "    NUM_ACTIONS = 7\n",
    "\n",
    "print(f\"Operation pool: {OPERATION_POOL}\")\n",
    "print(f\"Action space size: {ActionSpace.NUM_ACTIONS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full ArchitectureState class from architecture.py\n",
    "# (Paste the complete class here or import from module)\n",
    "\n",
    "# For notebook, we'll use a compact version that imports from the module\n",
    "exec(open('architecture.py').read())\n",
    "\n",
    "print(\"‚úÖ ArchitectureState class loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Architecture Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple test architecture\n",
    "test_arch = ArchitectureState.initialize_starter()\n",
    "\n",
    "print(\"Test Architecture:\")\n",
    "print(f\"  Nodes: {len(test_arch.nodes)}\")\n",
    "print(f\"  Edges: {len(test_arch.edges)}\")\n",
    "print(f\"  Depth: {test_arch.depth}\")\n",
    "print(f\"  Operations: {list(test_arch.operations.values())}\")\n",
    "print(f\"  Valid actions: {len(test_arch.get_valid_actions())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ GNN Models\n",
    "\n",
    "Graph neural network for encoding architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GNN models\n",
    "exec(open('gnn_models.py').read())\n",
    "\n",
    "print(\"‚úÖ GNN models loaded\")\n",
    "\n",
    "# Test GNN encoder\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "encoder = ArchitectureEncoder().to(device)\n",
    "print(f\"   Encoder parameters: {sum(p.numel() for p in encoder.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Novelty Metrics\n",
    "\n",
    "Measures for topological and scale creativity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load novelty metrics\n",
    "exec(open('novelty.py').read())\n",
    "\n",
    "print(\"‚úÖ Novelty metrics loaded\")\n",
    "\n",
    "# Test novelty computation\n",
    "reward_fn = RewardFunction(alpha=0.5, beta=0.35, gamma=0.15)\n",
    "test_reward, components = reward_fn.compute_reward(test_arch, performance=0.85)\n",
    "\n",
    "print(f\"\\nTest reward components:\")\n",
    "for key, value in components.items():\n",
    "    print(f\"  {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Architecture Evaluation\n",
    "\n",
    "Convert architectures to PyTorch models and train them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation code\n",
    "exec(open('evaluation.py').read())\n",
    "\n",
    "print(\"‚úÖ Evaluation code loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model from test architecture\n",
    "test_model = ConvNet(test_arch, num_classes=10).to(device)\n",
    "\n",
    "print(f\"Model created:\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in test_model.parameters()):,}\")\n",
    "\n",
    "# Test forward pass\n",
    "test_input = torch.randn(2, 3, 32, 32).to(device)\n",
    "test_output = test_model(test_input)\n",
    "print(f\"  Output shape: {test_output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ DQN Agent\n",
    "\n",
    "Reinforcement learning agent that discovers architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load agent code\n",
    "exec(open('agent.py').read())\n",
    "\n",
    "print(\"‚úÖ DQN agent loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Utilities & Visualization\n",
    "\n",
    "Functions for saving/loading and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load utils and visualization\n",
    "exec(open('utils.py').read())\n",
    "exec(open('visualize.py').read())\n",
    "\n",
    "print(\"‚úÖ Utilities loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== TRAINING CONFIGURATION =====\n",
    "\n",
    "CONFIG = {\n",
    "    'dataset': 'cifar10',        # 'mnist', 'fashion', 'cifar10'\n",
    "    'episodes': 1000,            # Number of training episodes\n",
    "    'eval_epochs': 3,            # Epochs per architecture during search\n",
    "    'final_epochs': 20,          # Epochs for final evaluation\n",
    "    'top_k': 20,                 # Number of top architectures to evaluate\n",
    "    'device': device,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Set seeds\n",
    "torch.manual_seed(CONFIG['seed'])\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(CONFIG['seed'])\n",
    "np.random.seed(CONFIG['seed'])\n",
    "random.seed(CONFIG['seed'])\n",
    "\n",
    "# Output directory\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "OUTPUT_DIR = f'results/{CONFIG[\"dataset\"]}_{timestamp}'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(f\"\\nOutput: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Initialize Agent & Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize agent\n",
    "agent = CreativityDQN(device=CONFIG['device'])\n",
    "\n",
    "print(f\"Agent initialized with {sum(p.numel() for p in agent.q_network.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train agent\n",
    "print(f\"\\nTraining for {CONFIG['episodes']} episodes...\\n\")\n",
    "\n",
    "best_archs, stats = agent.train(\n",
    "    num_episodes=CONFIG['episodes'],\n",
    "    update_freq=10,\n",
    "    eval_freq=50\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Training complete! Found {len(best_archs)} architectures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Visualize Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Episode rewards\n",
    "axes[0, 0].plot(stats['episode_rewards'])\n",
    "axes[0, 0].set_title('Episode Rewards')\n",
    "axes[0, 0].set_xlabel('Episode')\n",
    "axes[0, 0].set_ylabel('Reward')\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Training loss\n",
    "if stats['losses']:\n",
    "    axes[0, 1].plot(stats['losses'])\n",
    "    axes[0, 1].set_title('Training Loss')\n",
    "    axes[0, 1].set_xlabel('Update Step')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].grid(True)\n",
    "\n",
    "# Epsilon decay\n",
    "axes[1, 0].plot(stats['epsilons'])\n",
    "axes[1, 0].set_title('Epsilon Decay')\n",
    "axes[1, 0].set_xlabel('Episode')\n",
    "axes[1, 0].set_ylabel('Epsilon')\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# Reward distribution\n",
    "axes[1, 1].hist(stats['episode_rewards'], bins=50)\n",
    "axes[1, 1].set_title('Reward Distribution')\n",
    "axes[1, 1].set_xlabel('Reward')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'training_stats.png'), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Evaluating top {CONFIG['top_k']} architectures...\\n\")\n",
    "\n",
    "final_results = []\n",
    "\n",
    "for i, arch_data in enumerate(best_archs[:CONFIG['top_k']]):\n",
    "    arch = arch_data['architecture']\n",
    "    search_reward = arch_data['reward']\n",
    "    \n",
    "    print(f\"[{i+1}/{CONFIG['top_k']}]\")\n",
    "    print(f\"  Nodes: {len(arch.nodes)}, Depth: {arch.depth}, Width: {arch.avg_width:.1f}\")\n",
    "    \n",
    "    # Full training\n",
    "    final_acc = train_architecture(\n",
    "        arch,\n",
    "        epochs=CONFIG['final_epochs'],\n",
    "        device=CONFIG['device'],\n",
    "        subset_size=None\n",
    "    )\n",
    "    \n",
    "    print(f\"  Accuracy: {final_acc:.4f}\\n\")\n",
    "    \n",
    "    final_results.append({\n",
    "        'architecture': arch,\n",
    "        'search_reward': search_reward,\n",
    "        'final_accuracy': final_acc,\n",
    "        'trajectory': arch_data.get('trajectory', [])\n",
    "    })\n",
    "\n",
    "print(\"‚úÖ Evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Save All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "save_all_results(OUTPUT_DIR, best_archs, final_results, stats, CONFIG['dataset'])\n",
    "\n",
    "# Create visualizations\n",
    "create_results_report(OUTPUT_DIR)\n",
    "\n",
    "# Save agent\n",
    "agent.save(os.path.join(OUTPUT_DIR, 'agent.pt'))\n",
    "\n",
    "print(f\"\\n‚úÖ All results saved to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÜ Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create summary table\n",
    "summary_data = []\n",
    "for i, result in enumerate(sorted(final_results, key=lambda x: x['final_accuracy'], reverse=True)):\n",
    "    arch = result['architecture']\n",
    "    summary_data.append({\n",
    "        'Rank': i+1,\n",
    "        'Accuracy': result['final_accuracy'],\n",
    "        'Reward': result['search_reward'],\n",
    "        'Nodes': len(arch.nodes),\n",
    "        'Depth': arch.depth,\n",
    "        'Avg_Width': arch.avg_width,\n",
    "        'Parameters': arch.total_params,\n",
    "        'Skip_Connections': arch.num_skip_connections\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nBest Accuracy: {df['Accuracy'].max():.4f}\")\n",
    "print(f\"Average Accuracy: {df['Accuracy'].mean():.4f}\")\n",
    "print(f\"Std Accuracy: {df['Accuracy'].std():.4f}\")\n",
    "print(f\"\\nAverage Depth: {df['Depth'].mean():.1f}\")\n",
    "print(f\"Average Width: {df['Avg_Width'].mean():.1f}\")\n",
    "print(f\"Average Parameters: {df['Parameters'].mean():,.0f}\")\n",
    "\n",
    "print(\"\\nTop 10 Architectures:\")\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® Visualize Best Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "best = max(final_results, key=lambda x: x['final_accuracy'])\n",
    "best_arch = best['architecture']\n",
    "\n",
    "print(\"üèÜ BEST ARCHITECTURE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Accuracy: {best['final_accuracy']:.4f}\")\n",
    "print(f\"Reward: {best['search_reward']:.4f}\")\n",
    "print(f\"Nodes: {len(best_arch.nodes)}\")\n",
    "print(f\"Depth: {best_arch.depth}\")\n",
    "print(f\"Width: {best_arch.avg_width:.1f}\")\n",
    "print(f\"Parameters: {best_arch.total_params:,}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Visualize\n",
    "viz_path = os.path.join(OUTPUT_DIR, 'best_architecture.png')\n",
    "visualize_architecture(best_arch, save_path=viz_path,\n",
    "                      title=f\"Best Architecture (Acc: {best['final_accuracy']:.4f})\")\n",
    "display(Image(filename=viz_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Done!\n",
    "\n",
    "All results saved to `{OUTPUT_DIR}/`\n",
    "\n",
    "Open `report.html` to see the full interactive report!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
