{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîç Architecture Explorer\n",
    "\n",
    "Load and explore saved architectures from previous training runs.\n",
    "\n",
    "**Use this to:**\n",
    "- Load saved models (.pth files)\n",
    "- Explore architecture structures (.json files)\n",
    "- Visualize architectures\n",
    "- Compare different architectures\n",
    "- Use models for inference\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display, Image\n",
    "\n",
    "# Import modules\n",
    "from architecture import ArchitectureState, OPERATION_POOL\n",
    "from evaluation import ConvNet\n",
    "from utils import load_architecture_json, save_model_pth\n",
    "from visualize import visualize_architecture\n",
    "\n",
    "print(\"‚úÖ Modules loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ Select Results Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURE THIS ===\n",
    "# Path to your results directory\n",
    "RESULTS_DIR = 'demo_results/mnist_20241203_143022'  # Change this to your results folder\n",
    "\n",
    "# Verify directory exists\n",
    "if not os.path.exists(RESULTS_DIR):\n",
    "    print(f\"‚ùå Directory not found: {RESULTS_DIR}\")\n",
    "    print(f\"\\nAvailable directories:\")\n",
    "    if os.path.exists('demo_results'):\n",
    "        for d in os.listdir('demo_results'):\n",
    "            print(f\"  - demo_results/{d}\")\n",
    "    if os.path.exists('results'):\n",
    "        for d in os.listdir('results'):\n",
    "            print(f\"  - results/{d}\")\n",
    "else:\n",
    "    print(f\"‚úÖ Using results from: {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Load Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load summary\n",
    "summary_path = os.path.join(RESULTS_DIR, 'summary.json')\n",
    "with open(summary_path) as f:\n",
    "    summary = json.load(f)\n",
    "\n",
    "print(\"üìã Summary\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Dataset: {summary['dataset']}\")\n",
    "print(f\"Total Episodes: {summary['total_episodes']}\")\n",
    "print(f\"Architectures Explored: {summary['architectures_explored']}\")\n",
    "print(f\"Architectures Evaluated: {summary['architectures_evaluated']}\")\n",
    "print(f\"Best Accuracy: {summary['best_accuracy']:.4f}\")\n",
    "print(f\"Average Accuracy: {summary['avg_accuracy']:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìñ Load All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all results from JSONL\n",
    "results_path = os.path.join(RESULTS_DIR, 'results.jsonl')\n",
    "results = []\n",
    "\n",
    "with open(results_path) as f:\n",
    "    for line in f:\n",
    "        results.append(json.loads(line))\n",
    "\n",
    "print(f\"Loaded {len(results)} architectures\")\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "df = df.sort_values('final_accuracy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nTop 10 Architectures:\")\n",
    "display(df[['arch_id', 'final_accuracy', 'search_reward', 'depth', 'avg_width', 'total_params']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÜ Explore Best Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best architecture\n",
    "best_result = df.iloc[0]\n",
    "best_arch_id = best_result['arch_id']\n",
    "\n",
    "print(f\"üèÜ Best Architecture: {best_arch_id}\")\n",
    "print(\"=\"*60)\n",
    "for key, value in best_result.items():\n",
    "    if key != 'arch_id':\n",
    "        print(f\"{key:20s}: {value}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Load Architecture Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load architecture from JSON\n",
    "arch_path = os.path.join(RESULTS_DIR, 'architectures', f'{best_arch_id}.json')\n",
    "best_arch = load_architecture_json(arch_path)\n",
    "\n",
    "print(\"Architecture Details:\")\n",
    "print(f\"  Nodes: {best_arch.nodes}\")\n",
    "print(f\"  Edges: {best_arch.edges}\")\n",
    "print(f\"  Operations: {best_arch.operations}\")\n",
    "print(f\"  Channels: {best_arch.channels}\")\n",
    "print(f\"  Positions (depth): {best_arch.positions}\")\n",
    "\n",
    "# Operation distribution\n",
    "op_counts = {}\n",
    "for op in best_arch.operations.values():\n",
    "    op_counts[op] = op_counts.get(op, 0) + 1\n",
    "\n",
    "print(f\"\\nOperation Distribution:\")\n",
    "for op, count in sorted(op_counts.items()):\n",
    "    print(f\"  {op:15s}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® Visualize Best Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "viz_path = 'temp_visualization.png'\n",
    "visualize_architecture(\n",
    "    best_arch, \n",
    "    save_path=viz_path,\n",
    "    title=f\"{best_arch_id} - Accuracy: {best_result['final_accuracy']:.4f}\"\n",
    ")\n",
    "\n",
    "display(Image(filename=viz_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model weights\n",
    "model_path = os.path.join(RESULTS_DIR, 'models', f'{best_arch_id}.pth')\n",
    "checkpoint = torch.load(model_path)\n",
    "\n",
    "print(\"Checkpoint contents:\")\n",
    "print(f\"  Keys: {checkpoint.keys()}\")\n",
    "print(f\"  Timestamp: {checkpoint['timestamp']}\")\n",
    "print(f\"  Metadata: {checkpoint['metadata']}\")\n",
    "\n",
    "# Create model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = ConvNet(best_arch, num_classes=10).to(device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(f\"\\n‚úÖ Model loaded with {sum(p.numel() for p in model.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test inference with random input\n",
    "test_input = torch.randn(1, 3, 32, 32).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(test_input)\n",
    "    probabilities = torch.softmax(output, dim=1)\n",
    "    predicted_class = output.argmax(dim=1).item()\n",
    "\n",
    "print(\"Test Inference:\")\n",
    "print(f\"  Input shape: {test_input.shape}\")\n",
    "print(f\"  Output shape: {output.shape}\")\n",
    "print(f\"  Predicted class: {predicted_class}\")\n",
    "print(f\"  Confidence: {probabilities[0, predicted_class].item():.4f}\")\n",
    "print(f\"\\nTop 3 predictions:\")\n",
    "top3 = probabilities[0].topk(3)\n",
    "for prob, idx in zip(top3.values, top3.indices):\n",
    "    print(f\"  Class {idx.item()}: {prob.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Compare Multiple Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top 5 for comparison\n",
    "top_5 = df.head(5)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Accuracy comparison\n",
    "axes[0].bar(range(5), top_5['final_accuracy'])\n",
    "axes[0].set_title('Final Accuracy')\n",
    "axes[0].set_xlabel('Rank')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Depth comparison\n",
    "axes[1].bar(range(5), top_5['depth'])\n",
    "axes[1].set_title('Architecture Depth')\n",
    "axes[1].set_xlabel('Rank')\n",
    "axes[1].set_ylabel('Depth')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Width comparison\n",
    "axes[2].bar(range(5), top_5['avg_width'])\n",
    "axes[2].set_title('Average Width')\n",
    "axes[2].set_xlabel('Rank')\n",
    "axes[2].set_ylabel('Channels')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "# Parameters\n",
    "axes[3].bar(range(5), top_5['total_params'])\n",
    "axes[3].set_title('Total Parameters')\n",
    "axes[3].set_xlabel('Rank')\n",
    "axes[3].set_ylabel('Parameters')\n",
    "axes[3].grid(True, alpha=0.3)\n",
    "\n",
    "# Novelty scores\n",
    "axes[4].bar(range(5), top_5['topological_novelty'], alpha=0.7, label='Topological')\n",
    "axes[4].bar(range(5), top_5['scale_novelty'], alpha=0.7, label='Scale')\n",
    "axes[4].set_title('Novelty Scores')\n",
    "axes[4].set_xlabel('Rank')\n",
    "axes[4].set_ylabel('Novelty')\n",
    "axes[4].legend()\n",
    "axes[4].grid(True, alpha=0.3)\n",
    "\n",
    "# Scatter: Accuracy vs Parameters\n",
    "axes[5].scatter(df['total_params'], df['final_accuracy'], alpha=0.6)\n",
    "axes[5].set_title('Accuracy vs Parameters')\n",
    "axes[5].set_xlabel('Parameters')\n",
    "axes[5].set_ylabel('Accuracy')\n",
    "axes[5].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¨ Analyze Architecture Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all architectures and analyze patterns\n",
    "all_ops = []\n",
    "all_depths = []\n",
    "all_widths = []\n",
    "\n",
    "arch_dir = os.path.join(RESULTS_DIR, 'architectures')\n",
    "for arch_file in os.listdir(arch_dir):\n",
    "    if arch_file.endswith('.json'):\n",
    "        arch_path = os.path.join(arch_dir, arch_file)\n",
    "        arch = load_architecture_json(arch_path)\n",
    "        \n",
    "        all_ops.extend(arch.operations.values())\n",
    "        all_depths.append(arch.depth)\n",
    "        all_widths.append(arch.avg_width)\n",
    "\n",
    "# Operation frequency\n",
    "op_freq = {}\n",
    "for op in all_ops:\n",
    "    op_freq[op] = op_freq.get(op, 0) + 1\n",
    "\n",
    "print(\"üî¨ Architecture Patterns Analysis\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nOperation Frequency:\")\n",
    "for op, count in sorted(op_freq.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {op:15s}: {count:4d} ({count/len(all_ops)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nDepth Statistics:\")\n",
    "print(f\"  Min: {min(all_depths)}\")\n",
    "print(f\"  Max: {max(all_depths)}\")\n",
    "print(f\"  Mean: {sum(all_depths)/len(all_depths):.2f}\")\n",
    "print(f\"  Std: {pd.Series(all_depths).std():.2f}\")\n",
    "\n",
    "print(f\"\\nWidth Statistics:\")\n",
    "print(f\"  Min: {min(all_widths):.1f}\")\n",
    "print(f\"  Max: {max(all_widths):.1f}\")\n",
    "print(f\"  Mean: {sum(all_widths)/len(all_widths):.2f}\")\n",
    "print(f\"  Std: {pd.Series(all_widths).std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Find Interesting Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ Interesting Architectures\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Most novel topologically\n",
    "most_novel_topo = df.loc[df['topological_novelty'].idxmax()]\n",
    "print(f\"\\nüìê Most Topologically Novel:\")\n",
    "print(f\"  ID: {most_novel_topo['arch_id']}\")\n",
    "print(f\"  Accuracy: {most_novel_topo['final_accuracy']:.4f}\")\n",
    "print(f\"  Topo Novelty: {most_novel_topo['topological_novelty']:.4f}\")\n",
    "\n",
    "# Best depth/width ratio\n",
    "df['depth_width_ratio'] = df['depth'] / (df['avg_width'] + 1)\n",
    "extreme_ratio = df.loc[df['depth_width_ratio'].idxmax()]\n",
    "print(f\"\\nüìè Most Extreme Depth/Width Ratio:\")\n",
    "print(f\"  ID: {extreme_ratio['arch_id']}\")\n",
    "print(f\"  Accuracy: {extreme_ratio['final_accuracy']:.4f}\")\n",
    "print(f\"  Depth/Width: {extreme_ratio['depth_width_ratio']:.4f}\")\n",
    "\n",
    "# Most efficient (best accuracy per parameter)\n",
    "df['efficiency'] = df['final_accuracy'] / (df['total_params'] + 1)\n",
    "most_efficient = df.loc[df['efficiency'].idxmax()]\n",
    "print(f\"\\n‚ö° Most Efficient (Accuracy/Params):\")\n",
    "print(f\"  ID: {most_efficient['arch_id']}\")\n",
    "print(f\"  Accuracy: {most_efficient['final_accuracy']:.4f}\")\n",
    "print(f\"  Parameters: {most_efficient['total_params']:,}\")\n",
    "print(f\"  Efficiency: {most_efficient['efficiency']:.2e}\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Export Specific Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an architecture to export\n",
    "EXPORT_ARCH_ID = best_arch_id  # Change this to any arch_id you want\n",
    "\n",
    "# Load architecture\n",
    "export_path = os.path.join(RESULTS_DIR, 'architectures', f'{EXPORT_ARCH_ID}.json')\n",
    "export_arch = load_architecture_json(export_path)\n",
    "\n",
    "# Create model\n",
    "export_model = ConvNet(export_arch, num_classes=10)\n",
    "\n",
    "# Load weights\n",
    "model_path = os.path.join(RESULTS_DIR, 'models', f'{EXPORT_ARCH_ID}.pth')\n",
    "checkpoint = torch.load(model_path)\n",
    "export_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Save to current directory\n",
    "export_filename = f'{EXPORT_ARCH_ID}_exported.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': export_model.state_dict(),\n",
    "    'architecture_json': export_path,\n",
    "    'metadata': checkpoint['metadata']\n",
    "}, export_filename)\n",
    "\n",
    "print(f\"‚úÖ Exported model to: {export_filename}\")\n",
    "print(f\"\\nTo load this model:\")\n",
    "print(f\"  checkpoint = torch.load('{export_filename}')\")\n",
    "print(f\"  model.load_state_dict(checkpoint['model_state_dict'])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Summary\n",
    "\n",
    "You've explored:\n",
    "- ‚úÖ Loaded all saved architectures\n",
    "- ‚úÖ Visualized best architectures  \n",
    "- ‚úÖ Loaded trained model weights\n",
    "- ‚úÖ Tested inference\n",
    "- ‚úÖ Compared multiple architectures\n",
    "- ‚úÖ Analyzed patterns across all results\n",
    "- ‚úÖ Exported specific models\n",
    "\n",
    "**Next steps:**\n",
    "- Use exported models in your applications\n",
    "- Fine-tune models on new datasets\n",
    "- Analyze which architectural patterns work best\n",
    "- Run more training to discover better architectures"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
